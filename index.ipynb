{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use Lasso and ridge regression in Python\n",
    "- Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')\n",
    "backup = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import numpy as np\n",
    "\n",
    "# remove \"object\"-type features and SalePrice from `X`\n",
    "df1 = df.select_dtypes(exclude='object')\n",
    "X = df1.drop('SalePrice', axis=1)\n",
    "\n",
    "# Impute null values\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Create y\n",
    "y = df.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1460 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Train R^2 :\t0.8046400702344446\n",
      "Linear Test R^2 :\t0.8240865405545486\n",
      "\n",
      "Linear Train MSE :\t1186117094.297817\n",
      "Linear Test MSE :\t1232328149.8815475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "print(f'Linear Train R^2 :\\t{linreg.score(X_train, y_train)}')\n",
    "print(f'Linear Test R^2 :\\t{linreg.score(X_test, y_test)}\\n')\n",
    "print(f'Linear Train MSE :\\t{mean_squared_error(y_train, linreg.predict(X_train))}')\n",
    "print(f'Linear Test MSE :\\t{mean_squared_error(y_test, linreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't standardized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Linear Train R^2 :\t0.8047331105936881\n",
      "Scaled Linear Test R^2 :\t0.8242471379110129\n",
      "\n",
      "Scaled Linear Train MSE :\t1185552204.8617349\n",
      "Scaled Linear Test MSE :\t1231203115.7665255\n"
     ]
    }
   ],
   "source": [
    "linreg_stand = LinearRegression()\n",
    "linreg_stand.fit(X_train, y_train)\n",
    "print(f'Scaled Linear Train R^2 :\\t{linreg_stand.score(X_train, y_train)}')\n",
    "print(f'Scaled Linear Test R^2 :\\t{linreg_stand.score(X_test, y_test)}\\n')\n",
    "print(f'Scaled Linear Train MSE :\\t{mean_squared_error(y_train, linreg_stand.predict(X_train))}')\n",
    "print(f'Scaled Linear Test MSE :\\t{mean_squared_error(y_test, linreg_stand.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_cat which contains only the categorical variables\n",
    "X_cat = df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dummies\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "np.shape(X_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `X_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([pd.DataFrame(X_scaled), X_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled (w/cats) Linear Train R^2 :\t0.9394011383437874\n",
      "Scaled (w/cats) Linear Test R^2 :\t-1.1751732418154632e+18\n",
      "\n",
      "Scaled (w/cats) Linear Train MSE :\t367922663.5251142\n",
      "Scaled (w/cats) Linear Test MSE :\t8.232451748956811e+27\n"
     ]
    }
   ],
   "source": [
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, random_state=42)\n",
    "\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg_scaled_cats = LinearRegression()\n",
    "linreg_scaled_cats.fit(X_train, y_train)\n",
    "print(f'Scaled (w/cats) Linear Train R^2 :\\t{linreg_scaled_cats.score(X_train, y_train)}')\n",
    "print(f'Scaled (w/cats) Linear Test R^2 :\\t{linreg_scaled_cats.score(X_test, y_test)}\\n')\n",
    "print(f'Scaled (w/cats) Linear Train MSE :\\t{mean_squared_error(y_train, linreg_scaled_cats.predict(X_train))}')\n",
    "print(f'Scaled (w/cats) Linear Test MSE :\\t{mean_squared_error(y_test, linreg_scaled_cats.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2:\t 0.9367137158658911\n",
      "Testing r^2:\t 0.8966464099462678\n",
      "Training MSE:\t 384239201.64251727\n",
      "Testing MSE:\t 724023839.9951768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:\\t', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:\\t', lasso.score(X_test, y_test))\n",
    "print('Training MSE:\\t', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:\\t', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2:\t 0.9345920827385311\n",
      "Testing r^2:\t 0.9021283694468796\n",
      "Training MSE:\t 397120580.7626387\n",
      "Testing MSE:\t 685621019.4809843\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=10)\n",
    "lasso.fit(X_train, y_train)\n",
    "print('Training r^2:\\t', lasso.score(X_train, y_train))\n",
    "print('Testing r^2:\\t', lasso.score(X_test, y_test))\n",
    "print('Training MSE:\\t', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Testing MSE:\\t', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2:\t 0.9229902012717633\n",
      "Testing r^2:\t 0.8863756622794857\n",
      "Training MSE:\t 467560767.5003401\n",
      "Testing MSE:\t 795973601.5995784\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Training r^2:\\t', ridge.score(X_train, y_train))\n",
    "print('Testing r^2:\\t', ridge.score(X_test, y_test))\n",
    "print('Training MSE:\\t', mean_squared_error(y_train, ridge.predict(X_train)))\n",
    "print('Testing MSE:\\t', mean_squared_error(y_test, ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2:\t 0.899324376597647\n",
      "Testing r^2:\t 0.8793879667615905\n",
      "Training MSE:\t 611246523.4806529\n",
      "Testing MSE:\t 844924568.2660812\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Training r^2:\\t', ridge.score(X_train, y_train))\n",
    "print('Testing r^2:\\t', ridge.score(X_test, y_test))\n",
    "print('Training MSE:\\t', mean_squared_error(y_train, ridge.predict(X_train)))\n",
    "print('Testing MSE:\\t', mean_squared_error(y_test, ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "Lasso seems to be a bit more accurate than Ridge, both in terms of R^2 and MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low Ridge parameter coefficients: 4\n",
      "low Lasso parameter coefficients: 56\n"
     ]
    }
   ],
   "source": [
    "print('low Ridge parameter coefficients:', sum(abs(ridge.coef_) < 10**(-10)))\n",
    "print('low Lasso parameter coefficients:', sum(abs(lasso.coef_) < 10**(-10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
